Test Plan Document
==================

- [IDENTIFICATION INFORMATION](#identification-information)
  - [Product](#product)
  - [Project Description](#project-description)
  - [Testing Objectives](#testing-objectives)
  - [Features to be Tested](#features-to-be-tested)
  - [Features Not to Be Tested](#features-not-to-be-tested)
- [UNIT TEST](#unit-test)
  - [UNIT TEST STRATEGY / EXTENT OF UNIT TESTING:](#unit-test-strategy--extent-of-unit-testing)
  - [UNIT TEST CASES](#unit-test-cases)
- [REGRESSION TEST](#regression-test)
  - [Regression Test Strategy](#regression-test-strategy)
  - [Regression Test Cases](#regression-test-cases)
- [INTEGRATION TEST](#integration-test)
  - [Integration Test Strategy and Extent of Integration Testing](#integration-test-strategy-and-extent-of-integration-testing)
  - [Integration Test Cases](#integration-test-cases)
- [USER-ACCEPTANCE TEST (To be completed by the business office)](#user-acceptance-test-to-be-completed-by-the-business-office)
  - [User-Acceptance Test Strategy](#user-acceptance-test-strategy)
  - [User-Acceptance Test Cases](#user-acceptance-test-cases)
- [Test Deliverables](#test-deliverables)
- [Schedule](#schedule)
- [Risks](#risks)
- [Appendix](#appendix)


IDENTIFICATION INFORMATION
--------------------------

### Product

- **Hunting Stand Weather Manager:**

### Project Description

The "Hunting Stand Weather Manager" is software that seeks to help the user 
determine the best areas to hunt in a given property. This is accomplished by
comparing property and stand data entered by the user, with relevant weather 
data.
The main feature of this software is the stand layout. When viewing a property
the user will see each a list of each stand belonging to that group with a grade
assigned to it. This grade is generated by comparing a stand's cardinal
direction with the current wind direction of the properties general location.
By assigning a grade to each stand the user can easily determine at a glance 
which stands are suitable to hunt at at any given time.

### Testing Objectives

The main objective of this test plan is to define the scope and activities 
required to ensure the functionality, performance, and security of the hunting 
stand management system. That involves ensuring that the core grading logic
works accurately, that user data is stored securely, that API's are integrated 
to communicate successfully, and that the UI features of the Webapp are 
intuitive and easy to use.


### Features to be Tested
Account Management:
Validating login and logout, data isolation for each user, and account security. 
 
Stand and Property Management:
Creating, editing, and deleting stands and stand groups

Map Interface:
If integrated, using "find my location" on a mobile device.
Being able to create stands via map UI

Weather and Grading Logic:
Reliable API Data retrieval from OpenWeatherMap/Weather.gov, error handling for
faiures. Grading accuracy. Grading calculation for future dates.

UI:
Dashboard having ranked display, color coding, and visual compass icons. Being 
able to switch between properties and their dashboards. If implemented, the
calendar view.

Database:
Ensuring proper database relationships between Users, Stand Groups, and Stands. 
Ensuring that deleting a user removes all associated data. Verifying that system
relies on cached weather data when able.

### Features Not to Be Tested

While I will be testing for how weather data is handled, I will not be testing
the accuracy of weather data pulled from APIs. Comparing accuracies of different
weather data sources is out of scope for this project.


UNIT TEST
---------

### UNIT TEST STRATEGY / EXTENT OFl UNIT TESTING:

Evaluate new features and bug fixes introduced in this release. 
(Specify the properties of test environment: hardware, software, network etc.)

For unit testing I will perform automated testing on the web applications core 
features. Specifically individual functions like the grading algorithm, data
entry, and data security. A majority of the testing will be done on my laptop
running windows 11, and various mobile devices.

### UNIT TEST CASES

| \#  | OBJECTIVE | INPUT | EXPECTED RESULTS | TEST DELIVERABLES |
| --: | --------- | ----- | ---------------- | ----------------- |
|  1  | Grading Logic Perfect | Stand Degree 0°, Wind Degree 90° | Function returns Grade A 100 % | Test Log |
|  2  | Grading Logic Worst | Stand Degree 0°, Wind Degree 0° | Function returns Grade F 0% | Test Log |
|  3  | Grading Logic Mid | Stand Degree 0°, Wind Degree 45° | Function returns Grade C 45% | Test Log |
|  4  | User Creation | Name: Caleb Gumbers Email: cGumbers@email.com | User is created | Database Entry |
|  5  | Property Creation | Property Name: Family Land, lat:38.52, Long:77.33 | Property is Created| Database Entry |
|  6  | Stand Creation | Stand Name: Thickneck Landing, Stand Degree: 340 | Stand is created| Database Entry |
|  7  | One to Many User -> Property | Property has valid user_id association | Property is correctly associated with relevant User | Database Error Log |
|  8  | One to Many Property -> Stand | Stand has valid property_id association | Stand is correctly associated with relevant Property | Database Error Log |
|  9  | Cascading Delete | Delete a user from the database | All properties and stands associated with the user are also removed from the database | Database Error Log |
|  10  | User Login | User enters in valid username and password | User's account is loaded | Test Report |
|  11  | User Isolation | When User-A logs in | User A cannot See User-B's Data | Test Report |
|  12  | Password Security | A new user is created ? Check data base?| Verification of password hashing in database | 

REGRESSION TEST
---------------

Ensure that previously developed and tested software still performs after change.

### Regression Test Strategy

Evaluate all reports introduced in previous releases.

The goal of my regression test strategy is to confirm that any recent code 
changes or added features do not conflict with already existing system. 
This means ensuring that Users, Properties, and Stands can still be created
edited, and deleted with no issue. That the core grading logic for stand ranking
has not been altered. And that users are still able to securely login and view 
their own data.

### Regression Test Cases

| #   | OBJECTIVE | INPUT | EXPECTED RESULTS | OBSERVED |
| --: | --------- | ----- | ---------------- | -------- |
|  1  |User Stand Creation| Use "Create Stand" in UI and enter valid data | New stand is successfully added to the database and appears in user's dashboard | Test Log |
|  2  | Consistant Grader Logic | Provide a north facing stand with a south wind | Grader correctly returns an A Grade after Dashboard updates | Test log |
|  3  | Isolated Data | Login as User A; Try to view User B's data | Cannot View User B's Data | Observation? |
|  4  | Data Deletion Integrity - User | Deleting a User | All properties and stands associated with that user are removed from the database | Test Log |
|  5  | Account Persistence | User A logs in, go to dashboard, refresh page | User remains logged in on the dashboard | Observation |
|  6  | Data Deletion Integrity - Property | Deleting a Property | All stands associated with that property are removed from the database | Test Log |
|  7  | Weather API Data | Update wind data for specific location | System successfully requests, recieves, parses, and caches wind data | Test Log |
|  8  | Stand Editing | Edit name of existing stand | Database updates and data change is reflected on the Dashboard | Observation? | 
|  9  | Dashboard Ranking | View Dashboard with three or more stands with varying degrees | Stands are accurately sorted A - F, with A at the top of the list. | Observation |


INTEGRATION TEST
----------------

Combine individual software modules and test as a group.

### Integration Test Strategy and Extent of Integration Testing

Evaluate all integrations with locally developed shared libraries, with consumed services, and other touch points.

The goal of this integration test strategy is to validate the data exchanged
between the application frontend, backend, the server, and the API services.
This means varifying that wind data can be successfully requested, received and
manipulated from OpenWeatherMap/Weather.gov. That the app can correctly request
and recieve latitude/longitude data from the user's device. And confirming that 
when a stand is created or edited in the UI, the change is accurately written
to the database and retrieved correctly when displaying on the dashboard.

### Integration Test Cases

| #   | OBJECTIVE | INPUT | EXPECTED RESULTS | TEST DELIVERABLES |
| --: | --------- | ----- | ---------------- | ----------------- |
|  1  | Weather API Connection | Send valid coordinates to API | System recieves successful API Response containing correct weather data | Test Log |
|  2  | Weather API Error Handling | Simulate an invaid request | System displays a relevant error message rather than crashing | Error Log |
|  3  | Geolocation Integration | Click "Use my Location" or equivalent in UI | Browser prompts for geolocation data permission and fills in form with current GPS data | Observation |
|  4  | Weather Data Caching | User "A" and User "B" request weather update in the same location within the same update window | System fulfills the second request using cached data rather than making a new API Request | Server Log | 
|  5  | Authentication | Enter valid credentials into login page | Frontend successfully authenticates user info with backend and redirects to relevant dashboard | not sure | 
|  6  | Grader Refresh | Manually trigger weather data update for existing Property | Grader recalculates Dashboard correctly | Test Log |
|  7  | Click location on the map interface to create a new stand | The coordinate data from the map successfully passes to stand creation form | Observation | 



USER-ACCEPTANCE TEST
--------------------

Verify that the solution works for potential user. Include the method (e.g.,
heuristic, performance measures, thinking aloud, observation, questionnaire, 
interviews, etc.), the number of participants and demographics, the concent
form, *scenarios*, scripts to read, and data collection methods.

### User-Acceptance Test Strategy

(Explain how user acceptance testing will be accomplished.)
The goal of this testing is to ensure that the application and interface is 
intuitive and easy to use for the user. The main method of testing will be a 
two scripted scenario where (1) a user sets up a new property for hunting and
(2) the user checks the dashboard to prepare for a hunt within a certain time 
frame.

### User-Acceptance Test Cases

| #   | TEST ITEM | EXPECTED RESULTS | ACTUAL RESULTS | DATE |
| --: | --------- | ---------------- | -------------- | ---- |
|  1  |           |                  |                |      |
|  2  |           |                  |                |      |


Test Deliverables
-----------------

(List test deliverables, and links to them if available, including the following.)

-   Test Plan (this document itself)
-   Test Scripts
-   Defect/Enhancement Logs
-   Test Result Reports


Schedule
--------

(Provide a summary of the testing schedule, specifying key test milestones, 
and/or provide a link to the detailed schedule.)

Risks
-----

-   Weather API Downtime 
- Mitigation: Implement weather data caching to store and reuse the most recent
  successful update.
- Contingency: Display warning letting the user know that the system may be
  using outdated data. Allow for manual entry of wind data.
-   API Rate Limit
- Mitigation: API requests will be based on user need and on a 6-12 hour timer.
- Contingency: Rely on cached weather data


Appendix
--------

(Include any information that is helpful to reference.)
